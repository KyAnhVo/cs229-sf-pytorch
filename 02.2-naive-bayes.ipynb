{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "k = 5\n",
    "n = 10\n",
    "m = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(x: torch.Tensor, phi: torch.Tensor, p: torch.Tensor):\n",
    "    \"\"\" retun an y-vector prediction to given x, phi and p.\n",
    "\n",
    "    Given x is (m, n), phi is (n, k) and p is (k, 1), we perform\n",
    "    NB prediction on the matrices to get an y-vector prediction.\n",
    "    For k classes, each element in y_i in y is in [0,k)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    logPhi = phi.log()      # n, k\n",
    "    logP = p.log().T        # 1, k\n",
    "\n",
    "    scores = x @ logPhi + logP\n",
    "    return scores.argmax(dim=1, keepdim=True)\n",
    "\n",
    "def generateData(k: int, n: int, m: int):\n",
    "    # generate real P (probability of y matrix)\n",
    "    p = torch.randint(low=1, high=6, size=(k, 1), device=device).to(torch.float32)\n",
    "    PSum = p.sum(dim=0)\n",
    "    p = p / PSum\n",
    "\n",
    "    # generate real phi\n",
    "    phi = torch.randint(low=1, high=5, size=(n, k), device=device).to(torch.float32)\n",
    "    phiSum = phi.sum(dim=0, keepdim=True).expand(size=phi.size())\n",
    "    phi = phi / phiSum\n",
    "    phiNot = 1 - phi\n",
    "\n",
    "    # generate training x\n",
    "    x = torch.randint(low=0, high=2, size=(m, n), device=device).to(torch.float32)\n",
    "    xNot = 1 - x\n",
    "\n",
    "    # generate phi and p, also add temperature\n",
    "    \n",
    "    temperature = 0.3\n",
    "\n",
    "    logPhi = phi.log()\n",
    "    logPhiNot = phiNot.log()\n",
    "    logP = p.log().T.expand(size=(m, k))\n",
    "\n",
    "    # generate training y\n",
    "    yPercentages = x @ logPhi + xNot @ logPhiNot + logP\n",
    "    yPercentages = yPercentages / temperature\n",
    "    y = yPercentages.softmax(dim=1)\n",
    "    y = y.multinomial(num_samples=1)\n",
    "\n",
    "    return (x, y, phi, p)\n",
    "\n",
    "x, y, phiTrue, pTrue = generateData(k, n, m)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75.0,\n",
       " tensor([[1, 4, 3, 4, 4, 3, 2, 2, 2, 4, 2, 0, 1, 1, 3, 3, 4, 1, 1, 4]],\n",
       "        device='cuda:0'),\n",
       " tensor([[2, 4, 3, 4, 4, 3, 2, 2, 1, 4, 3, 3, 1, 1, 3, 3, 4, 1, 4, 4]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate real P (probability of y matrix)\n",
    "p = torch.randint(low=1, high=6, size=(k,), device=device)\n",
    "pSum = p.sum()\n",
    "p = p / pSum\n",
    "\n",
    "def accuracy(a: torch.Tensor, b: torch.Tensor) -> float:\n",
    "    assert a.shape == b.shape, f\"a={a.shape}, b={b.shape}\"\n",
    "    return (a == b).float().mean().item() * 100\n",
    "\n",
    "yPredict = prediction(x, phiTrue, pTrue)\n",
    "\n",
    "accuracy(yPredict, y), y.T, yPredict.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75.0,\n",
       " tensor([[1, 4, 3, 4, 4, 3, 2, 1, 4, 4, 4, 4, 1, 1, 3, 4, 4, 1, 1, 4]],\n",
       "        device='cuda:0'),\n",
       " tensor([[1, 4, 3, 4, 4, 3, 2, 2, 2, 4, 2, 0, 1, 1, 3, 3, 4, 1, 1, 4]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def paramFit(x: torch.Tensor, y: torch.Tensor, classCount: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    ''' Find phi and p that fits the Naive Bayes model\n",
    "\n",
    "    Args:\n",
    "        x           (torch.Tensor): (m, n) tensor, data\n",
    "        y           (torch.Tensor): (m, 1) tensor, output\n",
    "        classCount  (int):          amount of classes\n",
    "    Returns:\n",
    "        (phi, p) (tuple[torch.Tensor, torch.Tensor]): \n",
    "            phi is (n, k) tensor s.t. phi[i][j] = p(x_i | y = j) and\n",
    "            p is (k, 1) tensor s.t. p[i][0] = p(y = i)\n",
    "    '''\n",
    "\n",
    "    assert(x.size()[0] == y.size()[0])\n",
    "    assert(y.size()[1] == 1)\n",
    "    \n",
    "    m = x.size()[0]\n",
    "    n = x.size()[1]\n",
    "    k = classCount\n",
    "\n",
    "    y_onehot = torch.nn.functional.one_hot(y.squeeze(), num_classes=k).to(torch.float32)\n",
    "\n",
    "    phiNumerator = x.T @ y_onehot + 1\n",
    "    phiDenominator = y_onehot.sum(dim=0, keepdim=True).expand(size=phiNumerator.shape) + k\n",
    "    phi = phiNumerator / phiDenominator\n",
    "\n",
    "    P = y_onehot.mean(dim=0, keepdim=True).T\n",
    "\n",
    "    return phi, P\n",
    "\n",
    "phiPredict, pPredict = paramFit(x, y, k)\n",
    "yPredict = prediction(x, phiPredict, pPredict)\n",
    "\n",
    "accuracy(yPredict, y), yPredict.T, y.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
